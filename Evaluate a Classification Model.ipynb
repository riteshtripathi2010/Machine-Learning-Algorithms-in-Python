{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to properly evaluate Classification Models\n",
    "#What is the purpose of model evaluation, and what are common evaluation procedures\n",
    "#What is the usage of classification accuracy and what are some limitations\n",
    "#How does a confusion matrix describe the performance of a classifier\n",
    "#What metrics can be computed from a confusion matrix\n",
    "#How can you adjust classifier performance by Changing classification threshold\n",
    "#What is the purpose of ROC\n",
    "#How does AUC area under curve differ from classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Briefly review of model evaluation\n",
    "#Model Evaluation answers: how do i choose between different models\n",
    "#between k nearest and logistic regression\n",
    "#or selecting optimal tunning paramters\n",
    "#or choosing different sets of features\n",
    "#you need a Model Evaluation Procedure to estimate how well a model will generalize to out of sample data\n",
    "#Requires a model evaluation metric to quantify the model performance\n",
    "\n",
    "#We have talked different types of Model Evaluation Procedures\n",
    "#Training and Testing on same data\n",
    "    #Rewards overly complex models that overfit the training data and wont necessarily generalize\n",
    "#Train/Test split\n",
    "    #better estimate out of sample perfromance but still a high variance estimate\n",
    "    #useful due to its speed, simplicity and flexibility    \n",
    "#K Fold Cross Validation\n",
    "    #Systematically create K train test splits and average the results together\n",
    "    #Even better estimate of out of sample performance\n",
    "    #Runs k times slower than train/test split\n",
    "    #training and testing on same data is classical cause of over fitting, in which you over built complex model\n",
    "        #that will not generalize to new data\n",
    "    #train/test is still better than k fold cross validation due to its speed\n",
    "    \n",
    "    \n",
    "#You always need Evaluation Metrics\n",
    "    #Regression Problems: Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "    #Classification Problems: Classifcation Accuracy\n",
    "    \n",
    "\n",
    "#Classification Accuracy, its strengths and accuracy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pima = pd.read_csv('/Users/riteshtripathi/Downloads/data.csv')\n",
    "pima.head()\n",
    "\n",
    "\n",
    "#url = 'https://arch....'\n",
    "#col_names = ['pregnant', ...]\n",
    "#pima = pd.re..(url, header = None, names = col_names)\n",
    "\n",
    "#we are to find diabets for a paitent if given health details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Qns: Can we predicit the diabetes status of a patient given their health measurements\n",
    "#choosing X features\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "y = pima.Outcome\n",
    "X = pima[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split X and y into training and testing data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a logistic regression model on training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver = 'lbfgs')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions for testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6770833333333334\n"
     ]
    }
   ],
   "source": [
    "#Calculation Accuracy: Percent of correct prediction\n",
    "#Calculate Accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "#here y_test contains true response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Null Accuracy: Accuracy that could be achieved by always predicting the most frequent class\n",
    "#any time u use classification accuracy, its better to use compare with null accuracy\n",
    "\n",
    "#examine the class distribution of the testing set, using pandas series\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3229166666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the percentage of ones\n",
    "y_test.mean()\n",
    "#32 percent of y_test are ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate percent of zeros\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since 67 is larger than 32, we would say 67 is the Null Accuracy\n",
    "#a dumb model predicts that a paitent doesnt have diabetes will be 67 percent of times\n",
    "#when we compare null accuracy with model accuracy\n",
    "    #this shows our model is not good, 67 comparing with 69\n",
    "#this tells us one weakness of classification accuracy\n",
    "    #classification accuracy doesnt tell us anything about underlying distribution of the testing set\n",
    "\n",
    "#How to calcualte Null Accuracy in one go:(for binary classification problems coded as 0 and 1)\n",
    "max(y_test.mean(), 1 - y_test.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.677083\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Null Accuracy for multi class classification problems(for 3 or more classes)\n",
    "#they will only work if y_test is pandas series\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred:  [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#lets look at another weakness of classification accuracy\n",
    "#Comparing True and Predicted Response\n",
    "#print the first 25 true and predicted responses\n",
    "print('True: ', y_test.values[0:25])\n",
    "print('Pred: ', y_pred_class[0:25])\n",
    "\n",
    "#the problem we see is that\n",
    "#when true is always 0, it predicts as 0\n",
    "#when true is 1, pred is rarely 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion\n",
    "#Classification accuracy is the easiest classification metric to understand\n",
    "#but it doesnt tell you the underlying distribution of response values\n",
    "#And it doesnt tell you that what types of errors your classifier is making\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  16]\n",
      " [ 46  16]]\n"
     ]
    }
   ],
   "source": [
    "#To over come all the issues in Classification Accuracy, We use Confusion MAtrix\n",
    "#Confusion Matrix: Table that describes the performance of a classifcation model\n",
    "\n",
    "#Important: first argument is true values, second argument is predicted values\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "#here true values = y_test\n",
    "#here predicted values = y_pred_class\n",
    "#adapt to this habbit\n",
    "\n",
    "#this is a 2*2 matrix, because its a binary classification\n",
    "#it there were 5 classes, it would be 5*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: -c: line 0: syntax error near unexpected token `('\r\n",
      "/bin/sh: -c: line 0: `[small confusion matrix](images/09_confusion_matrix_1.png)'\r\n"
     ]
    }
   ],
   "source": [
    "#above doesnt tells us anything, lets use diagram to explain\n",
    "![small confusion matrix](images/09_confusion_matrix_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It shows\n",
    "#When actual 0:it predicted 0 114 times\n",
    "#When actual 0: it predicted 1, 16 times\n",
    "\n",
    "#When Actual 1: it predicted 0's, 47 times\n",
    "#When Actual 1: it predicted 1's, 15 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When a confusion matrix is used for a binary problem\n",
    "#True Positives: we correctly predicited that they do have diabetes\n",
    "    #in this case, classifier correctly predicted 16 cases, patients have diabetes\n",
    "#True Negatives: We correctly predicted that they dont have diabtes\n",
    "    #classifier predicted, 114 cases,  patients do not have diabetes\n",
    "#False Positives: We incorrectly predicted that they do have diabetes, Type 1 error\n",
    "    #In 12 cases, classifier incorrectly predicted that a patient has diabetes and yet they do not\n",
    "#False Negatives: We incorrectly predicted that they dont have diabetes, Type 2 error\n",
    "    #classifier incorrectly predicted 46 cases, that a patient doesnt have diabetes, but infact they do have diabetes\n",
    "    \n",
    "\n",
    "#its conventional, class coded as 0 as -ve class\n",
    "#class coded as 1 as +ve class\n",
    "#therefore correctly predicting 1 values is True Positives\n",
    "#Correctly predicitng as 0 values is True Negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics Computed from a Confusion Matrix\n",
    "#Classification Accuracy: Over all how often is the classifier correct?\n",
    "#Classification Accuracy can be calculated from COnfusion Matrix\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Error: Over all how often is the classifier incorrect\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Senstivity\n",
    "#When the actual value is positive, how often is the prediction correct?\n",
    "#Also known as True Positive Rate or Recall\n",
    "    #How senstive is the classifier to detecting poisitve instances\n",
    "print(metrics.recall_score(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specificity\n",
    "#When the actual value is negative, how often is the predicition correct\n",
    "    #How specific (or selective)is the classifier in predicting positive instances\n",
    "#no per formula in scikit learn, we have to calcualte manually\n",
    "TN / float(TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False Positive Rate\n",
    "#When the actual value is negative, how often is the prediction incorrect\n",
    "FP / float(TN + FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "#When a positive value is predicted, how often is prediction correct\n",
    "    #How precise is the classifier when predicting positive instances?\n",
    "TP / float(TP + FP)\n",
    "print(metrics.precision_score(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Many other metrics can be computed: F1 SCore, Mathews Corelation coefficient etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion\n",
    "#Confusion metrix gives you a more complete picture of how your classifier is performing\n",
    "#Also allows you to compute various classification metrics and these metrics can guide your model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which metrics should you focus on?\n",
    "#Choice of metrics depends on business objective\n",
    "#Spam Filter: positive class is spam, Optimize your precision or specificity because false negatives (spam goes to inbox)\n",
    "    #are more acceptable than false positives (non spam is caught by the spam filter)    \n",
    "#Fradulent Transaction Detector(positive class is fraud): Optimize for senstivity because false positives \n",
    "    #(normal transactions that are flagged as possible fraud) are more acceptable than false negatives\n",
    "    #(fraudlent transactions are not detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adjusting the classification thresholds\n",
    "#How to modify the performance of a classifier by adjusting the classification threshold\n",
    "#print the first 10 predicted responses\n",
    "logreg.predict(X_test)[0:10]\n",
    "#its a one dimensional array of 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61405867, 0.38594133],\n",
       "       [0.7505398 , 0.2494602 ],\n",
       "       [0.74167648, 0.25832352],\n",
       "       [0.60291327, 0.39708673],\n",
       "       [0.88426611, 0.11573389],\n",
       "       [0.87695895, 0.12304105],\n",
       "       [0.50819992, 0.49180008],\n",
       "       [0.44582289, 0.55417711],\n",
       "       [0.77950769, 0.22049231],\n",
       "       [0.25853303, 0.74146697]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the first 10 predicted probabilites of class membership\n",
    "logreg.predict_proba(X_test)[0:10, :]\n",
    "#here each row represnts one observation\n",
    "#each column represents paritcular class\n",
    "\n",
    "#col on left is col 0 and right is 1\n",
    "#shows us the probability of eeach observation is of class 0\n",
    "#same for class1\n",
    "#each row adds upto 1\n",
    "\n",
    "#why we do this step, is to see the probability of someone having a probability of getting diabetes and to contact them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38594133, 0.2494602 , 0.25832352, 0.39708673, 0.11573389,\n",
       "       0.12304105, 0.49180008, 0.55417711, 0.22049231, 0.74146697])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the first 10 predicted probabilites for class 1 (we are isolating pred prob)\n",
    "logreg.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store above predicted probs for class1\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]#i want all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are going to plot histogram of these probabilites of class1\n",
    "#to help demonstarte how adjusting the classification threshold can impact the performance of the model\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram of predicted probabilites\n",
    "plt.hist(y_pred_prob, bins = 8)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Historgame of prdeicted probabilites')\n",
    "plt.xlabel('Predicted probability of diabetes')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "#histogram shows the distribution of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd bar shows that, 30 percent of observations had values between 0.2 and 0.3\n",
    "#class1 is rarely predicted since small minority of testing setup observations had predicted probability above \n",
    "#the threshold\n",
    "#you can adjust the senstivity and specificity by adjustting the threshold\n",
    "#For Eg, if we decreasee the threshold for predicting diabetes in order to increase the senstivity of the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.38594133 0.2494602  0.25832352 0.39708673 0.11573389 0.12304105\n 0.49180008 0.55417711 0.22049231 0.74146697].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ec631039751c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#predict diabetes if the predicted probability is greater than 0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#it will return 1 for all above class 0.3 and 0 otherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mbinarize\u001b[0;34m(X, threshold, copy)\u001b[0m\n\u001b[1;32m   1769\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \"\"\"\n\u001b[0;32m-> 1771\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1772\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.38594133 0.2494602  0.25832352 0.39708673 0.11573389 0.12304105\n 0.49180008 0.55417711 0.22049231 0.74146697].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#there was an explanation on above for lowering the threshold, i skipped that\n",
    "#lets lower the threshold from 0.5 to 0.3\n",
    "#predict diabetes if the predicted probability is greater than 0.3\n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize(y_pred_prob, 0.3)[0]\n",
    "\n",
    "#it will return 1 for all above class 0.3 and 0 otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38594133, 0.2494602 , 0.25832352, 0.39708673, 0.11573389,\n",
       "       0.12304105, 0.49180008, 0.55417711, 0.22049231, 0.74146697])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the first 10 predicted probabilites\n",
    "y_pred_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the first 10 predicted classes with lower threshold\n",
    "y_pred_class[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-010f93795e50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#previous confusion matrix default to 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion' is not defined"
     ]
    }
   ],
   "source": [
    "#previous confusion matrix default to 0.5\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "118 12\n",
    "47 15\n",
    "\n",
    "is the confusion result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  16]\n",
      " [ 46  16]]\n"
     ]
    }
   ],
   "source": [
    "#new confusion metrics for 0.3 threshild\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7419354838709677\n"
     ]
    }
   ],
   "source": [
    "#senstivity has increased (used to be 0.24)\n",
    "print(46/float(46+16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "#specifity has decreased (used to be 0.91)\n",
    "print(80/float(80+50))\n",
    "\n",
    "#this happened, because most of the observations moved from class 0 to class 1\n",
    "#that guarantees number of false positives will increase\n",
    "#and true negatives will decrease\n",
    "#which decreases the specificity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion\n",
    "#threshold 0.5 is used by default (for binary problems) to convert predicted probabilites into class predictions\n",
    "#threshold can be adjusted to increase senstivity or specificity depending on your business objectives\n",
    "#Sensitivity and Specificity have an inverse relationship\n",
    "#increasing one will always decrease the other\n",
    "\n",
    "#remember that adjusting should the last step of building model\n",
    "#most of the time should be selecting best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC and Area under the curve (AUC)\n",
    "#we have been seeing differernt threshold, it would be better if we could see how senstivity and specificity\n",
    "#are affected by various threshold, without actually changing the threshold\n",
    "\n",
    "#Ans: plot the roc curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [192, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5ce5fd36421f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#first argument is true values, second argument is predicted probabilites\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[1;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 622\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [192, 10]"
     ]
    }
   ],
   "source": [
    "#first argument is true values, second argument is predicted probabilites\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROc curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Speciifty)')\n",
    "plt.ylabel('True Positive Rate (Sensititvity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve can help you to choose a threshold that balances sensitivity and specificity in a way\n",
    "#that makes sense for your particular context\n",
    "\n",
    "#You cant actually see the threshold used to generate the curve on the ROC curve itself\n",
    "\n",
    "#the plot roc tells u that if you want to achieve sensitivity of 0.9, you should choose specifity of 0.4\n",
    "#above, i couldnt get the roc curve, but using answers from prof class\n",
    "#from roc, the top most left corner shows high sensitvity and specificity \n",
    "#it can visually help you to choose threshold, that makes sense to your problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that accepts a threshold and prints sensitivity and specificty\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Senstivity:', tpr[thresholds > threshold][-1],\n",
    "    print('Specificity:', fpr[thresholds > threshold][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tpr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0aea75dd96da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-9720589fddb2>\u001b[0m in \u001b[0;36mevaluate_threshold\u001b[0;34m(threshold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#define a function that accepts a threshold and prints sensitivity and specificty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     print('Senstivity:', tpr[thresholds > threshold][-1],\n\u001b[0m\u001b[1;32m      4\u001b[0m     print('Specificity:', fpr[thresholds > threshold][-1]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tpr' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.5)\n",
    "#the graph generated \n",
    "#Sens: 0.24\n",
    "#Spe: 0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_threshold(0.3)\n",
    "##sens: 0.74\n",
    "#spec: 0.61\n",
    "\n",
    "#remember: roc curve is a plot of senstivity vs 1-speciificity for all clasification threshold from 0 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [192, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-773c9ea9ace5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#AUC is the percentage of the ROC plot that is underneath the curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#first argument is true values, second argument is predicted probabliites\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    353\u001b[0m     return _average_binary_score(\n\u001b[1;32m    354\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[0;32m--> 327\u001b[0;31m                                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[1;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 622\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [192, 10]"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "#the area under the curve, in this case its big auc\n",
    "#auc is used as a single number summary of the performance of the classifier\n",
    "#to alternative to classification accuracy\n",
    "\n",
    "#AUC is the percentage of the ROC plot that is underneath the curve\n",
    "#first argument is true values, second argument is predicted probabliites\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this gives 0.72, \n",
    "#best auc for any classifier is 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC is useful as a single number summary of classifier performance\n",
    "#if you randomly choose one positive and one negative observations, AUC represnts the likelihood that your classifier \n",
    "#will assign a higher preidcited probability to the positive observation\n",
    "\n",
    "#AuC is useful even when there is high class imbalance(unlike classification accuracy)\n",
    "#auc is better than classification accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425071225071225"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Claculate Cross Validate AUC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv = 10, scoring = 'roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix Advantage\n",
    "#Allows you to calculate a variety of metrics\n",
    "#USeful for multi class problems(more than two response classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC / AUC advantages\n",
    "#Does not require you to set a classification threshold\n",
    "#still useful when there is high class imbalance\n",
    "\n",
    "#Howevre they are less interpretable than the confusin matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to use both, confusion matrix and roc/auc\n",
    "#in confusion matrix many metrics can be caluclated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
